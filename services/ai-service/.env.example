# ============================================================================
# AI SERVICE - Environment Configuration
# ============================================================================
# This file contains all environment variables for the AI/ML service.
# Copy this file to .env and update with your actual values.
#
# Required variables are marked with [REQUIRED]
# Optional variables are marked with [OPTIONAL]
# ============================================================================

# ============================================================================
# APPLICATION SETTINGS
# ============================================================================

# [OPTIONAL] Application name
APP_NAME=ApplyForUs AI Service

# [OPTIONAL] Application version
APP_VERSION=1.0.0

# [REQUIRED] Runtime environment
# Values: development | production | test
ENVIRONMENT=development

# [OPTIONAL] Enable debug mode
DEBUG=true

# [OPTIONAL] Log level
# Values: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================

# [REQUIRED] Host to bind the server
HOST=0.0.0.0

# [REQUIRED] Service port number
PORT=5000

# ============================================================================
# AI PROVIDERS - OpenAI
# ============================================================================
# Obtain API key from: https://platform.openai.com/api-keys
# See ops/docs/environment-setup.md for detailed setup instructions
# ============================================================================

# [REQUIRED] OpenAI API key
# Format: sk-...
OPENAI_API_KEY=sk-your-openai-key-here

# [OPTIONAL] OpenAI organization ID (for team accounts)
# OPENAI_ORG_ID=org-...

# [OPTIONAL] Default OpenAI model
# Options: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
# OPENAI_MODEL=gpt-4-turbo-preview

# [OPTIONAL] Max tokens per request
# OPENAI_MAX_TOKENS=4096

# ============================================================================
# AI PROVIDERS - Anthropic Claude
# ============================================================================
# Obtain API key from: https://console.anthropic.com/settings/keys
# See ops/docs/environment-setup.md for detailed setup instructions
# ============================================================================

# [REQUIRED] Anthropic API key
# Format: sk-ant-...
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# [OPTIONAL] Default Claude model
# Options: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
# ANTHROPIC_MODEL=claude-3-opus-20240229

# ============================================================================
# AI PROVIDERS - Azure OpenAI (Alternative to OpenAI)
# ============================================================================
# Use Azure OpenAI Service for enterprise compliance
# Obtain from: Azure Portal > Azure OpenAI > Keys and Endpoint
# ============================================================================

# [OPTIONAL] Azure OpenAI endpoint URL
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# [OPTIONAL] Azure OpenAI API key
# AZURE_OPENAI_API_KEY=<your-azure-openai-key>

# [OPTIONAL] Azure OpenAI deployment name
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# [OPTIONAL] Azure OpenAI API version
# AZURE_OPENAI_API_VERSION=2024-02-15-preview

# ============================================================================
# VECTOR DATABASE - Pinecone
# ============================================================================
# Obtain credentials from: https://app.pinecone.io/
# Used for: Semantic search, resume-job matching
# See ops/docs/environment-setup.md for detailed setup instructions
# ============================================================================

# [REQUIRED] Pinecone API key
PINECONE_API_KEY=your-pinecone-key-here

# [REQUIRED] Pinecone environment/region
# Examples: us-west1-gcp, us-east1-gcp, eu-west1-aws
PINECONE_ENVIRONMENT=us-west1-gcp

# [REQUIRED] Pinecone index name
PINECONE_INDEX_NAME=applyforus-vectors

# ============================================================================
# LLM CONFIGURATION
# ============================================================================

# [OPTIONAL] Default LLM provider
# Values: openai, anthropic, azure
DEFAULT_LLM_PROVIDER=openai

# [OPTIONAL] Model temperature (0.0-1.0, higher = more creative)
LLM_TEMPERATURE=0.7

# [OPTIONAL] Maximum response tokens
LLM_MAX_TOKENS=2000

# [OPTIONAL] Embedding model for vector generation
EMBEDDING_MODEL=text-embedding-ada-002

# [OPTIONAL] Embedding dimension (must match model output)
EMBEDDING_DIMENSION=1536

# ============================================================================
# JOB MATCHING CONFIGURATION
# ============================================================================

# [OPTIONAL] Number of top matches to return
MATCH_TOP_K=50

# [OPTIONAL] Minimum match score threshold (0.0-1.0)
MIN_MATCH_SCORE=0.6

# [OPTIONAL] Weight for skill matching (0.0-1.0)
SKILL_MATCH_WEIGHT=0.4

# [OPTIONAL] Weight for experience matching (0.0-1.0)
EXPERIENCE_MATCH_WEIGHT=0.3

# [OPTIONAL] Weight for location matching (0.0-1.0)
LOCATION_MATCH_WEIGHT=0.15

# [OPTIONAL] Weight for culture fit matching (0.0-1.0)
CULTURE_MATCH_WEIGHT=0.15

# ============================================================================
# REDIS CONFIGURATION - Caching
# ============================================================================
# Production: Azure Cache for Redis (SSL/TLS on port 6380)
# Local Dev: Use localhost:6379 or Docker Compose
# Used for: Response caching, rate limiting, embeddings cache
# ============================================================================

# [REQUIRED] Redis host
REDIS_HOST=applyforus-redis.redis.cache.windows.net

# [REQUIRED] Redis port (6380 for Azure SSL, 6379 for local)
REDIS_PORT=6380

# [OPTIONAL] Redis database number (0-15)
REDIS_DB=0

# [REQUIRED] Redis password/access key
REDIS_PASSWORD=<your-redis-access-key-here>

# [REQUIRED] Enable TLS for Redis connection
REDIS_TLS=true

# [OPTIONAL] Enable SSL (alias for TLS)
REDIS_SSL=true

# [OPTIONAL] Cache TTL in seconds (default: 1 hour)
CACHE_TTL=3600

# --- Local Development Override (use in .env.local) ---
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_PASSWORD=
# REDIS_TLS=false

# ============================================================================
# EXTERNAL SERVICES
# ============================================================================
# Production: Use Kubernetes internal DNS
# Local Dev: Use localhost URLs
# ============================================================================

# [OPTIONAL] Auth service URL for token validation
AUTH_SERVICE_URL=http://auth-service.applyforus.svc.cluster.local:8001

# [OPTIONAL] Job service URL for job data
JOB_SERVICE_URL=http://job-service.applyforus.svc.cluster.local:4002

# --- Local Development Override (use in .env.local) ---
# AUTH_SERVICE_URL=http://localhost:8001
# JOB_SERVICE_URL=http://localhost:4002

# ============================================================================
# RATE LIMITING
# ============================================================================

# [OPTIONAL] Maximum requests per rate limit period
RATE_LIMIT_REQUESTS=100

# [OPTIONAL] Rate limit period in seconds
RATE_LIMIT_PERIOD=60

# ============================================================================
# CORS CONFIGURATION
# ============================================================================

# [REQUIRED] Comma-separated list of allowed origins
CORS_ORIGINS=https://applyforus.com,https://www.applyforus.com,https://api.applyforus.com

# [OPTIONAL] Allow credentials in CORS requests
CORS_ALLOW_CREDENTIALS=true

# --- Local Development Override (use in .env.local) ---
# CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# ============================================================================
# FEATURE FLAGS
# ============================================================================

# [OPTIONAL] Enable AI-powered resume suggestions
# AI_SUGGESTIONS_ENABLED=true

# [OPTIONAL] Enable resume optimization features
# RESUME_OPTIMIZATION_ENABLED=true

# [OPTIONAL] Enable salary prediction
# SALARY_PREDICTION_ENABLED=true

# ============================================================================
# MONITORING (Optional)
# ============================================================================

# [OPTIONAL] Enable Prometheus metrics
# ENABLE_METRICS=true

# [OPTIONAL] Metrics endpoint port
# METRICS_PORT=9090

# [OPTIONAL] Azure Application Insights
# APPLICATIONINSIGHTS_CONNECTION_STRING=

# [OPTIONAL] Sentry DSN for error tracking
# SENTRY_DSN=

# ============================================================================
# NOTES
# ============================================================================
# 1. Never commit .env files with real API keys to version control
# 2. OpenAI API has rate limits - monitor usage in dashboard
# 3. Anthropic Claude has different pricing tiers - choose model accordingly
# 4. Pinecone free tier has limitations on vector count and queries
# 5. For production:
#    - Use Azure Key Vault for secret management
#    - Consider Azure OpenAI for enterprise compliance
#    - Monitor API costs and implement usage limits
# 6. Vector embedding dimension must match the model being used:
#    - text-embedding-ada-002: 1536 dimensions
#    - text-embedding-3-small: 1536 dimensions
#    - text-embedding-3-large: 3072 dimensions
# ============================================================================
